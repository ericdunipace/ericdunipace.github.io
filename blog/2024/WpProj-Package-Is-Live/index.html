<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> WpProj hits CRAN! | Eric A. Dunipace </title> <meta name="author" content="Eric A. Dunipace"> <meta name="description" content="My first package is finally live on CRAN "> <meta name="keywords" content="Dunipace, Eric, optimal, transport, optimal transport, Harvard, UCLA, DGSOM, Berkeley, Stanford, psychiatry, biostats, biostatistics, statistics, stats, machine learning, Zubizarreta, Trippa, Eric Dunipace, causal, inference"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?5b15871aca489a433d98b6c24c83b78b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ericdunipace.github.io/blog/2024/WpProj-Package-Is-Live/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Eric</span> A. Dunipace </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">WpProj hits CRAN!</h1> <p class="post-meta"> Created in February 02, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Edit (1/30/2025):</strong> *This package was archived on CRAN in November 2024 due to a package it depended on being archived. Working on getting it back up ASAP *</p> <hr> <p>This package was quite a mess. It was the first one I’d ever decided to do and filled with na”ivet’e and hubris, I thought it would be a good idea to make a package to load all my functions. It definitely took a long time—especially because a lot of the code was adapting someone else’s C++ code to run for my purpose!—but I think it’s not too bad. There are some places I see that would be obvious places to improve the models but required more work than I currently have time to put in, unfortunately.</p> <h2 id="what-does-the-package-do">What does the package do?</h2> <p>Basically, this package was my round about way of re-inventing \(L_p\) regression. Only slightly kidding. The basic idea is as follows.</p> <p>Say you have some arbitrarily complex model, \(f\), that takes covariates \(x\), and generates a set of predictions, call them \(\hat{y}\in \mathcal{Y}\), that follow a distribution \(\mu\), with an empirical counterpart \(\hat{\mu}\). Now say this model is really hard to interpret how the \(x\)’s affect the predictions. Let’s say we have another class of models, \(g\), that are easy to interpret. Say these are linear models that typically have the form \(x\beta\). We will denote predictions from this model as \(\hat{\eta}\) and let them have some unspecified distribution \(\nu\) and empirical counterpart \(\hat{\nu}\). (Note that since the \(x\)’s are considered fixed, the distribution is actually coming from the \(\beta\)’s, i.e. \(x\beta \sim \nu\))</p> <p>It’d be nice if we could use this set of interpretable models from \(g\) to help us understand what’s happening in \(f\). Ideally, these models in \(g\) would be close in some sense to \(f\). We desire</p> <ol> <li>Fidelity: predictions from our \(g\) models should be close to \(f\)</li> <li>Interpretability: we should be able to understand what’s happening in \(g\). This also implies our models can’t have too many coefficients.</li> </ol> <p>Let’s address each of these in turn. For 1, we need some way of ensuring predictive distributions are close to one another. One such metric is the \(p\)-Wasserstein distance, defined as</p> \[W_p(\hat{\mu}, \hat{\nu}) = \left( \inf_\pi \int \|\hat{y} - \hat{\nu}\|^p \pi(d\hat{y}, d\hat{\nu}) \right)^{1/p}.\] <p>Then we seek to minimize \(\inf_\hat{\nu} W_p(\hat{\mu}, \hat{\nu})^p.\)</p> <p>Now, for 2. Since the parameter space of \(\hat{\nu}\) could be quite large if the dimensionality of \(x\) is large, then we might not still have an interpretable model—I’d argue that a 1000 covariate regression model is <strong>not</strong>, in fact, interpretable!</p> <p>Going back to our minimization problem, we want to add some kind of penalty for large parameter distributions</p> \[\inf_\hat{\nu} W_p(\hat{\mu}, \hat{\nu})^p + P_\lambda (\hat{\nu}).\] <p>We should note that \(\hat{\nu} = x \hat{\beta}\). So, we need someway of reducing the dimensionality of the \(x\)’s. But fortunately, for linear models there’s a decades old method of doing just that!</p> <p>Rather than focusing on the \(x\)’s, we focus on reducing the dimensions of \(\beta\) using a penalty like the group Lasso:</p> \[P_\lambda (\beta) = \lambda \| \beta^{(1)} \|_2 + \lambda \|\beta^{(2)}\|_2 + ...\] <p>Finally, if we let the number of atoms in empricical distributions be equal, then the problem will reduce to</p> \[\inf_\beta \sum_i \left\| \hat{y}_i - x \beta_i\right\|_p^p + \lambda \sum_j \left \|\beta^{(j)}\right\|_2.\] <p>Cool!</p> <h2 id="lets-see-an-example">Let’s see an example</h2> <p>Ok, say we have some covariate data, \(X\), and an outcome, \(Y\). In many cases, the size of \(X\) can be quite large—in the 100s or 1000s. The question of then how to interpret this model can be tough: what covariates do we focus on? Moreover, the model itself may not be interpretable to begin with, such as from a Gaussian Process, a neural network, etc.</p> <h3 id="estimating-a-data-model">Estimating a data model</h3> <p>For exposition, we will generate our data from a hard to interpret, non-linear model and then fit a Bayesian Gaussian Process regression to estimate the response surface. The set-up will be somewhat complicated but it’s basically to generate complicated data and fit a complicated model.</p> <p>First, let’s assume our data is drawn from the following distributions. Let \(p = 10\) and \(n = 1000\). Take</p> \[X_i \sim \mathcal{N} (0, \mathbb{I}_p)\] <p>and</p> \[Y_i = \beta_0 + \sum_{k=1}^p \beta_k X_{i,k} + \sum_{k=1,k' &gt;k }^p \alpha_{k,k'} X_{i,k} X_{i,k'} + \epsilon_i\] <p>where \(\epsilon_{1:n} \sim^{iid} \mathcal{N}(0,1)\). We can generate the parameters of this generating function by taking \(\beta_0, \beta_{1:p}, \alpha \sim \mathcal{N}(0,1)\) and \(\epsilon_{1:n} \sim \mathcal{N}(0,1)\)</p> <p>Then, assume for some reason we know the true model (this is so we can run all of the methods for our package). And we will fit a Bayesian regression model directly on this model.</p> <p>We can assume normal priors on the coefficients (which will be the same as the data generating process above), and a half-normal prior on the standard deviation: \(\sigma \sim \mathcal{N}^{+}(0,1)\)</p> <p>We can then fit this model with the following <code class="language-plaintext highlighter-rouge">R</code> code:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">rstan</span><span class="p">)</span><span class="w">

</span><span class="c1"># Simulated Data</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span><span class="w">
</span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="o">^</span><span class="m">10</span><span class="w">
</span><span class="n">p</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span><span class="w">

</span><span class="c1"># parameters</span><span class="w">
</span><span class="n">beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">choose</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="m">2</span><span class="p">))</span><span class="w">
</span><span class="n">beta_0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">

</span><span class="c1"># data</span><span class="w">
</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">p</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w">
</span><span class="n">mm</span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">.</span><span class="o">*</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="w">
</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">mm</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">beta</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta_0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">))</span><span class="w">

</span><span class="n">code</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s1">'
data {
  int N;
  int P;
  vector[N] Y;
  matrix[N,P] X;
}
parameters {
  vector[P] beta;
  real&lt;lower=0&gt; sigma;
  real beta_0;
}
model {
  vector[N] mu_raw = X * beta + beta_0;
  
  beta_0 ~ normal(0,1);
  beta ~ normal(0,1);
  sigma ~ normal(0,1);
  Y ~ normal(mu_raw, sigma);
}
generated quantities {
  vector[N] mu = X * beta + beta_0;
}
'</span><span class="w">

</span><span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">stan</span><span class="p">(</span><span class="n">model_code</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">code</span><span class="p">,</span><span class="w"> 
            </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">P</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ncol</span><span class="p">(</span><span class="n">mm</span><span class="p">),</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mm</span><span class="p">),</span><span class="w">
            </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">chains</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">cores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h3 id="interpretable-model">Interpretable model</h3> <p>We can estimate an interpretable model, which essentially ammounts to fitting regression to the samples. How we do this can vary for our methods. Since we <em>know</em> the true model, we may simply seek to turn the covariates on our off and get our set of interpretable coefficients. Alternatively, we may want to find an approximate model with new coefficients. We can do both in the framework briefly described above.</p> <p>However, it is important to consider <em>what</em> we want to interpret. We could want to know how the model roughly functions globally, or which covariates could be the most important, but we may also want to know which covariates are driving the prediction for a single individual and consider the most important ones.</p> <p>Let’s say we’re interested in the 5th individual in our data. We can pul their data</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_mm</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">mm</span><span class="p">)</span><span class="w">
</span><span class="n">X_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">X_mm</span><span class="p">[</span><span class="m">5</span><span class="p">,]</span><span class="w">
</span></code></pre></div></div> <p>And then we can run our interpretable models. We first run our set that can get interpretable models for a single data point–i.e., by simply turning coefficients on or off that best predict the data:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">WpProj</span><span class="p">)</span><span class="w">

</span><span class="c1"># get parameters</span><span class="w">
</span><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">pars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mu"</span><span class="p">)</span><span class="o">$</span><span class="n">mu</span><span class="w">
</span><span class="n">beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">do.call</span><span class="p">(</span><span class="s2">"cbind"</span><span class="p">,</span><span class="w"> </span><span class="n">extract</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">pars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"beta_0"</span><span class="p">,</span><span class="s2">"beta"</span><span class="p">)))</span><span class="w">

</span><span class="c1"># get prediction</span><span class="w">
</span><span class="n">mu_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mu</span><span class="p">[,</span><span class="m">5</span><span class="p">]</span><span class="w">
  
</span><span class="c1"># get interpretable models            </span><span class="w">
</span><span class="n">bp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">WpProj</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">eta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu_test</span><span class="p">,</span><span class="w"> </span><span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w">
             </span><span class="n">power</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"binary program"</span><span class="p">,</span><span class="w">
             </span><span class="n">solver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"ecos"</span><span class="p">,</span><span class="w">
             </span><span class="n">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">display.progress</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w">

</span><span class="n">approx</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">WpProj</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">eta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu_test</span><span class="p">,</span><span class="w"> </span><span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w">
                 </span><span class="n">power</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"binary program"</span><span class="p">,</span><span class="w">
                 </span><span class="n">solver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lasso"</span><span class="p">,</span><span class="w">
             </span><span class="n">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">display.progress</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w">
</span></code></pre></div></div> <p>We can also fit a model that adapts the coefficients. To do so, we need to create a pseudo neighborhood round our point of interest</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">mvtnorm</span><span class="p">)</span><span class="w">

</span><span class="n">pp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ncol</span><span class="p">(</span><span class="n">mm</span><span class="p">)</span><span class="w"> 

</span><span class="c1"># generate the neighborhood arround the point</span><span class="w">
</span><span class="n">X_neigh</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mvtnorm</span><span class="o">::</span><span class="n">rmvnorm</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X_test</span><span class="p">[</span><span class="m">-1</span><span class="p">],</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cov</span><span class="p">(</span><span class="n">X_mm</span><span class="p">[,</span><span class="m">-1</span><span class="p">])</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="w">

</span><span class="c1"># get predictions for the neighborhood</span><span class="w">
</span><span class="n">mu_neigh</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">X_neigh</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span><span class="w">

</span><span class="c1"># get projection</span><span class="w">
</span><span class="n">proj</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">WpProj</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">X_neigh</span><span class="p">),</span><span class="w"> </span><span class="n">eta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu_neigh</span><span class="p">,</span><span class="w"> 
               </span><span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w">
               </span><span class="n">power</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"L1"</span><span class="p">,</span><span class="w">
               </span><span class="n">solver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lasso"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h3 id="performance-evaluation">Performance Evaluation</h3> <p>For our individual, they have an average predicted value of -6.7314591.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check WpR2</span><span class="w">
</span><span class="n">rp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">WpProj</span><span class="o">::</span><span class="n">ridgePlot</span><span class="p">(</span><span class="n">fit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"BP"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bp</span><span class="p">,</span><span class="w">
                                    </span><span class="s2">"approxBP"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">approx</span><span class="p">,</span><span class="w">
                                    </span><span class="s2">"projection"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">proj</span><span class="p">),</span><span class="w">
                          </span><span class="n">full</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu_test</span><span class="w">
                          </span><span class="p">)</span><span class="w">

</span><span class="n">print</span><span class="p">(</span><span class="n">rp</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <p><img src="/Users/eifer/GoogleDrive/ericdunipace.github.io/_posts/2024-02-02-WpProj-Package-Is-Live_files/figure-gfm/unnamed-chunk-5-1.png" alt=""></p> <p>We can see that the interpretable models do a better job of predicting as covariates are added but we might need more than just 10 covariates to really do a good job here.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check WpR2</span><span class="w">
</span><span class="n">wpr2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">WpProj</span><span class="o">::</span><span class="n">WPR2</span><span class="p">(</span><span class="n">predictions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu_test</span><span class="p">,</span><span class="w">
             </span><span class="n">projected_model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"BP"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bp</span><span class="p">,</span><span class="w">
                                    </span><span class="s2">"approxBP"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">approx</span><span class="p">,</span><span class="w">
                                    </span><span class="s2">"projection"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">proj</span><span class="p">),</span><span class="w">
             </span><span class="n">base</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">))</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">wpr2</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <p><img src="/Users/eifer/GoogleDrive/ericdunipace.github.io/_posts/2024-02-02-WpProj-Package-Is-Live_files/figure-gfm/unnamed-chunk-6-1.png" alt=""></p> <p>This last statistic functions kinda like \(R^2\) values in regression except it is measuring how close one is between a null model and the original predictions.</p> <h2 id="extensions">Extensions</h2> <p>One obvious extension is to have arbitrary transformations of the preditive function \(x\beta\). This would be useful in the case where we have something like predictions on a probability space and we want our coefficients to be selected such that they do the best job of predicting on that space rather than the linear predictor space:</p> \[\inf_\beta \sum_i \| \hat{y}_i - h(x \beta_i)\|_p^p + ...\] <p>This may also allow the models to have uses in other applications, which hopefully I will be working on soon!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/bias-variance/">The Bias-Variance Trade-off</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/RcppCGAL-updates/">RcppCGAL updated</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/TSP/">The Traveling Salesman Problem: Installing Concorde on Mac Catalina with CPLEX</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/DNN-playground/">Deep Neural Network Playground</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/rqpen-bug/">Bug alert in rqPen!</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Eric A. Dunipace. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>